% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/get.conf.sets.R
\name{get.conf.sets}
\alias{get.conf.sets}
\title{Select confounders and confounding variables for genes in a regulatory network}
\usage{
get.conf.sets(
  data,
  scale.data = TRUE,
  n_v,
  n_t,
  n_c,
  skip.V = FALSE,
  skip.T = FALSE,
  skip.C = FALSE,
  T.measure = c("partial", "marginal"),
  C.measure = T.measure,
  blocksize = 100,
  FDRcontrol = c("qvalue", "bonferroni", "none"),
  V.FDRcontrol = FDRcontrol,
  T.FDRcontrol = FDRcontrol,
  C.FDRcontrol = FDRcontrol,
  WZ.FDRcontrol = FDRcontrol,
  adjust_by = c("individual", "all", "none"),
  V.adjust_by = adjust_by,
  T.adjust_by = adjust_by,
  C.adjust_by = adjust_by,
  WZ.adjust_by = adjust_by,
  fdr = 0.05,
  lambda = 0.05,
  pi0.method = c("smoother", "boostrap"),
  alpha = 0.01,
  parallel = FALSE,
  cl = parallel::getDefaultCluster(),
  chunk.size = NULL,
  verbose = 0,
  save.list = FALSE,
  save.path = "/path/to/save/location/"
)
}
\arguments{
\item{data}{\code{matrix} or \code{dataframe} of size \code{N} samples by \code{m} variables
where the first \code{n_v} columns represents genetic variants, the following
\code{n_t} columns represent target genes (e.g. expression values), and the next \code{n_c} columns
represent potential confounding variables (e.g. sex, age, other genes).
Hence \code{m} must equal \code{n_t+n_v+n_c} or more.}

\item{scale.data}{logical scalar, should the data be scaled before processing?
Scaling refers here to standardization, \code{i.e.} subtracting the sample mean
and dividing by the sample standard deviation as achieved by \link{scale}. Only
genes and confounders are scaled, variants are not scaled even when
\code{scale.data = TRUE} (the default).}

\item{n_v, n_t, n_c}{numeric scalars, numbers of respectively \code{T}-nodes (genes/expression),
\code{V}-nodes (variants) and \code{C}-nodes (candidate confounding variables) in the
genomic network. The number of columns of \code{data} must be \code{n_t+n_v+n_c} or more.}

\item{skip.V, skip.T, skip.C}{logical, should the selection of respectively
\code{V}-nodes, \code{T}-nodes, or \code{C}-nodes be skipped? If \code{TRUE},
the corresponding selection is skipped and an empty list is returned. This can be
useful when a dataset is expanded with only one or two types of nodes, and there
is no need to select again confounding variables from the set(s) that remained unchanged.}

\item{T.measure, C.measure}{characters, indicating the association measures to
be used for different selections. One of \code{"partial"} for conditional
Pearson's correlation given \code{V}-nodes, and \code{"marginal"} for correlation
coefficient. The measure used for \code{V}-nodes selection is always the
marginal correlation coefficient.}

\item{FDRcontrol, T.FDRcontrol, C.FDRcontrol, V.FDRcontrol}{characters indicating
the FDR control methods to be used for different selections.
One of \code{"none"}, \code{"qvalue"} (see \link[qvalue]{qvalue}), or
\code{"bonferroni"} (see \link[stats]{p.adjust}).
If any of \code{T.FDRcontrol}, \code{C.FDRcontrol}, \code{V.FDRcontrol} is missing,
\code{FDRcontrol} is used, otherwise \code{FDRcontrol} is ignored.}

\item{adjust_by, T.adjust_by, C.adjust_by, V.adjust_by}{character indicating the
adjustment scheme for tests. One of \code{"none"} (no adjustment is desired),
\code{"individual"} (adjust p-values for each gene separately),
and \code{"all"} (adjust all p-values for all genes at once).
If any of \code{T.adjust_by}, \code{C.adjust_by}, \code{V.adjust_by} is missing,
\code{adjust_by} is used, otherwise \code{adjust_by} is ignored.}

\item{fdr, lambda, pi0.method, alpha}{See \link[MRGN]{get.conf.matrix}
(\code{selection_fdr} is used there for \code{fdr}).}

\item{parallel}{logical, should computations be parallelized?}

\item{cl, chunk.size}{a cluster object (\code{cl}) for parallel computations,
and a numeric scalar (\code{chunk.size}) to schedule parallel tasks.
Only used if \code{parallel = TRUE}.}

\item{save.list}{(logical) if TRUE the output is saved as a \code{.RData}
object (default = FALSE).}

\item{save.path}{string specifying the path name of the output list to be save
as a \code{.RData} structure. Only used if \code{save.list = TRUE}.}
}
\value{
a list with elements:
}
\description{
Build a set of confounding variables for genes in a genomic network including
genes (e.g. expression values), genetic variants, and confounders (e.g. sex, age,
PC scores from whole-genome expression) by testing marginal or partial associations
of each potential confounding variable and each gene. For each gene, the function
finds variants and/or other genes (in the network) that can confound the
regulatory mechanisms between a particular gene and another target gene.
}
\details{
This function is a wrapper for \link{get.conf.matrix}.
For a graph \code{G(V, T, C)} where \code{V} is the set of genetic variants,
\code{T} is the set of gene expressions, and \code{C} is the set of candidate
confounding variables in the network; \link{get.conf.sets} performs
three independent tasks.
\describe{
\item{V-node selection:}{ the \emph{marginal} association between each gene (\code{T}-node) and
each variant (\code{V}-node) is tested using a \emph{t}-test. If none of \code{V.adjust_by}
and \code{adjust_by} is \code{'none'}, then either all the tests involving a
particular \code{T}-node (when \code{adjust_by = 'individual'}), or all the tests
involving all \code{T}-nodes (when \code{adjust_by = 'all'}) are adjusted for
multiple comparison using the method \code{V.FDRcontrol}. All \code{V}-nodes
significantly associated with a particular \code{T}-node are then retained as
selected confounding variables for the \code{T}-node.}
\item{T-node selection:}{ the process is similar to \emph{V-node selection} except
that here, the associations between each \code{T}-node and all other \code{T}-nodes
in the network are tested, and the association measure between two \code{T}-nodes can
be partial (the default) or marginal correlation (specified via \code{T.measure}).
When \code{T.measure = "partial"}, partial correlations are computed given all
\code{V}-nodes in the network, and \emph{z}-tests are used instead of \emph{t}-tests.}
\item{C-node selection:}{ this step has two sub-steps. The first sub-step is a pre-selection
which is similar to \emph{T-node selection}, except that the association of each \code{T}-node
with each \code{C}-node is tested. The results is a pool of confounding variables
that can include true confounders (\code{U}-nodes) on one hand (\code{U}-nodes
are marginally uncorrelated with the \code{V}-nodes in the network), and
intermediate variables (\code{W}-node) and common children (\code{Z}-node)
on the other hand (\code{W} and \code{Z}-nodes are marginally correlated
with some \code{V}-nodes). The second sub-step thus tests for marginal
association between all \code{V}-nodes and each pre-selected \code{C}-node,
to assign the later as a confounder (\code{U}-node) or not (\code{W} or
\code{Z}-node).}
}
}
\seealso{
\link{get.conf.matrix}{MRGN}.
}
